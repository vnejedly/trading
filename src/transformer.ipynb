{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import List, Iterator, Tuple\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
    "from pprint import pprint\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frood/sources/python/m-factory/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    input_dim = 30\n",
    "    features_hidden_1_dim =1024\n",
    "    news_hidden_1_dim = 1024\n",
    "    common_hidden_1_dim = 1024\n",
    "    common_hidden_2_dim = 1024\n",
    "    model_dim = 512\n",
    "    num_heads = 8\n",
    "    num_layers = 8\n",
    "    output_dim = 3\n",
    "    max_seq_length = 512\n",
    "    news_embed_size = 768\n",
    "    dropout = 0.2\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bert_model = \"ProsusAI/finbert\"\n",
    "\n",
    "print(Config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsWrapper:\n",
    "    tokenizer: AutoTokenizer\n",
    "    news_batch: List[List[List[str]]]\n",
    "    flattened: List[str]\n",
    "    tokenized: BatchEncoding\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: AutoTokenizer,\n",
    "        news_batch: List[List[List[str]]]\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.news_batch = news_batch\n",
    "        self._flatten()\n",
    "        self._tokenize()\n",
    "\n",
    "    def get_encoding(\n",
    "        self, bert_output: BaseModelOutputWithPoolingAndCrossAttentions\n",
    "    ) -> torch.Tensor:\n",
    "        cls_tokens = bert_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "        index = 0\n",
    "        unflattened = []\n",
    "\n",
    "        for sequence in self.news_batch:\n",
    "            unflattened_sequence = []\n",
    "\n",
    "            for step in sequence:\n",
    "                step_length = len(step)\n",
    "                unflattened_sequence.append(\n",
    "                    self._combine_step_news(cls_tokens[index:index+step_length])\n",
    "                )\n",
    "                index += step_length\n",
    "\n",
    "            unflattened.append(torch.stack(unflattened_sequence))\n",
    "\n",
    "        return torch.stack(unflattened)\n",
    "\n",
    "    def _flatten(self):\n",
    "        self.flattened = []\n",
    "        for sequence in self.news_batch:\n",
    "            for step in sequence:\n",
    "                for sentence in step:\n",
    "                    self.flattened.append(sentence)\n",
    "\n",
    "    def _tokenize(self):\n",
    "        self.tokenized = self.tokenizer(\n",
    "            self.flattened, padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _combine_step_news(vectors: torch.Tensor) -> torch.Tensor:\n",
    "        # Compute the row-wise average\n",
    "        return vectors.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "    config: Config\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.features_hidden_1 = nn.Linear(config.input_dim, config.features_hidden_1_dim)\n",
    "        self.features_hidden_2 = nn.Linear(config.features_hidden_1_dim, config.common_hidden_1_dim)\n",
    "        \n",
    "        self.news_bert = AutoModel.from_pretrained(config.bert_model)\n",
    "        self.news_hidden_1 = nn.Linear(config.news_embed_size, config.news_hidden_1_dim)\n",
    "        self.news_hidden_2 = nn.Linear(config.news_hidden_1_dim, config.common_hidden_1_dim)\n",
    "        \n",
    "        self.common_hidden_1 = nn.Linear(config.common_hidden_1_dim, config.common_hidden_2_dim)\n",
    "        self.common_hidden_2 = nn.Linear(config.common_hidden_2_dim, config.model_dim)\n",
    "\n",
    "        self.positional_encoding = self._create_positional_encoding(config.max_seq_length, config.model_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=config.model_dim, nhead=config.num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=config.num_layers)\n",
    "        self.final_projection = nn.Linear(config.model_dim, config.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.activation_gelu = nn.GELU()\n",
    "\n",
    "        self.to(config.device)\n",
    " \n",
    "    def forward(\n",
    "        self,\n",
    "        features: torch.Tensor, # (batch_size, sequence_length, input_dim)\n",
    "        news: NewsWrapper,  # (batch_size, sequence_length, bert_embed_size)\n",
    "    ) -> Tuple[\n",
    "        torch.Tensor, # (batch_size, sequence_length, model_dim)\n",
    "        torch.Tensor, # (batch_size, sequence_length, model_dim)\n",
    "        torch.Tensor, # (batch_size, sequence_length, output_dim)\n",
    "    ]:\n",
    "        features = features.to(self.config.device)\n",
    "\n",
    "        news_bert = self.news_bert(**{\n",
    "            key: value.to(self.config.device) \n",
    "            for key, value in news.tokenized.items()\n",
    "        })\n",
    "\n",
    "        features = self.features_hidden_1(features)\n",
    "        features = self.activation_gelu(features)\n",
    "        features = self.dropout(features)\n",
    "        features = self.features_hidden_2(features)\n",
    "\n",
    "        news_hidden = self.news_hidden_1(news.get_encoding(news_bert))\n",
    "        news_hidden = self.activation_gelu(news_hidden)\n",
    "        news_hidden = self.dropout(news_hidden)\n",
    "        news_hidden = self.news_hidden_2(news_hidden)\n",
    "\n",
    "        common = features + news_hidden\n",
    "        common = self.activation_gelu(common)\n",
    "        common = self.dropout(common)\n",
    "        common = self.common_hidden_1(common)\n",
    "        common = self.activation_gelu(common)\n",
    "        common = self.dropout(common)\n",
    "        model = self.common_hidden_2(common)\n",
    "\n",
    "        return self.apply_transformer(model)\n",
    "    \n",
    "    def apply_transformer(\n",
    "        self, \n",
    "        common: torch.Tensor # (batch_size, sequence_length, model_dim)\n",
    "    ) -> Tuple[\n",
    "        torch.Tensor, # (batch_size, sequence_length, model_dim)\n",
    "        torch.Tensor, # (batch_size, sequence_length, model_dim)\n",
    "        torch.Tensor, # (batch_size, sequence_length, output_dim)\n",
    "    ]:\n",
    "        common = common.to(self.config.device)\n",
    "        transformer_input = common + self.positional_encoding[:, :common.size(1), :]\n",
    "        transformer_output = self.transformer_encoder(transformer_input)\n",
    "        \n",
    "        return transformer_input, transformer_output, self.final_projection(transformer_output)\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        features: torch.Tensor, # (batch_size, sequence_length, input_dim)\n",
    "        news_wrapper: NewsWrapper, # (batch_size, sequence_length, bert_embed_size)\n",
    "        future_steps: int\n",
    "    ) -> torch.Tensor: # (batch_size, future_steps, output_dim)\n",
    "        self.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        # use the full model for the initial prediction\n",
    "        tr_inputs, tr_outputs, step_predictions = self.forward(\n",
    "            features, news_wrapper\n",
    "        )\n",
    "\n",
    "        # get the prediction for the last token\n",
    "        predictions.append(step_predictions[:, -1, :])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(future_steps - 1):\n",
    "                tr_inputs = torch.cat((\n",
    "                    tr_inputs[:, 1:, :], \n",
    "                    tr_outputs[:, -1:, :]\n",
    "                ), dim=1)\n",
    "\n",
    "                # use the apply_transformer method for subsequent predictions\n",
    "                tr_inputs, tr_outputs, step_predictions = self.apply_transformer(\n",
    "                    tr_inputs\n",
    "                )\n",
    "\n",
    "                # get the prediction for the last token\n",
    "                predictions.append(step_predictions[:, -1, :])\n",
    "\n",
    "        # return predictions\n",
    "        return torch.stack(predictions, dim=1)\n",
    "    \n",
    "    def freeze_bert(self, freeze: bool = True):\n",
    "        for param in self.news_bert.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "\n",
    "    def get_params_count(self, trainable: bool = False) -> int:\n",
    "        return sum(param.numel() for param in self.parameters() if ((not trainable) or param.requires_grad))\n",
    "    \n",
    "    def _create_positional_encoding(\n",
    "        self, max_seq_length: int, model_dim: int\n",
    "    ) -> torch.Tensor:\n",
    "        pe = torch.zeros(max_seq_length, model_dim)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, model_dim, 2).float() * (-math.log(10000.0) / model_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        return nn.Parameter(pe, requires_grad=False).to(self.config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.865795 Million parameters\n",
      "torch.Size([2, 10, 3])\n",
      "tensor([[[ 0.0583, -0.5177,  0.1569],\n",
      "         [-0.1305, -0.1571, -0.1989],\n",
      "         [-0.2078,  0.0415, -0.3686],\n",
      "         [-0.1813,  0.1612, -0.4192],\n",
      "         [-0.1127,  0.1667, -0.4001],\n",
      "         [-0.0730,  0.1627, -0.3799],\n",
      "         [-0.0423,  0.1504, -0.3645],\n",
      "         [-0.0171,  0.1410, -0.3506],\n",
      "         [ 0.0064,  0.1316, -0.3367],\n",
      "         [ 0.0269,  0.1226, -0.3201]],\n",
      "\n",
      "        [[ 0.0522, -0.5234,  0.1530],\n",
      "         [-0.1350, -0.1569, -0.2025],\n",
      "         [-0.2113,  0.0438, -0.3722],\n",
      "         [-0.1835,  0.1638, -0.4229],\n",
      "         [-0.1143,  0.1689, -0.4036],\n",
      "         [-0.0742,  0.1644, -0.3824],\n",
      "         [-0.0431,  0.1516, -0.3663],\n",
      "         [-0.0176,  0.1418, -0.3514],\n",
      "         [ 0.0060,  0.1320, -0.3371],\n",
      "         [ 0.0267,  0.1227, -0.3202]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.bert_model)\n",
    "\n",
    "news_wrapper = NewsWrapper(tokenizer, [\n",
    "    [\n",
    "        [\n",
    "            \"I am a sentence\", \n",
    "            \"I am another sentence\", \n",
    "            \"Hello world\", \n",
    "            \"Just a quite longer sentence to test the padding\",\n",
    "        ],\n",
    "        [\n",
    "            \"So long and thanks for all the fish\", \n",
    "        ],\n",
    "        [\n",
    "            \"I am another sentence\", \n",
    "            \"Hello world\", \n",
    "        ]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            \"Hello world\", \n",
    "            \"Just a quite longer sentence to test the padding\",\n",
    "        ],\n",
    "        [\n",
    "            \"So long and thanks for all the fish\",\n",
    "            \"Hello world\", \n",
    "        ],\n",
    "        [\n",
    "            \"I am another sentence\", \n",
    "            \"Hello world\", \n",
    "            \"Just a quite longer sentence to test the padding\",\n",
    "        ]\n",
    "    ]\n",
    "])\n",
    "\n",
    "input_features = torch.rand(2, 3, config.input_dim).to(config.device)\n",
    "\n",
    "self = TimeSeriesTransformer(config)\n",
    "# raw_input, raw_output, output = self(input_features, news_wrapper)\n",
    "\n",
    "\n",
    "self.freeze_bert(True)\n",
    "print(self.get_params_count(True) / 1e6, \"Million parameters\")\n",
    "\n",
    "predictions = self.predict(input_features, news_wrapper, 10)\n",
    "\n",
    "print(predictions.shape)\n",
    "pprint(predictions)\n",
    "\n",
    "# print(raw_input.shape)\n",
    "# print(raw_output.shape)\n",
    "# print(output.shape)\n",
    "\n",
    "# print(input_features)\n",
    "\n",
    "# outputs = bertModel(**news_wrapper.tokenized)\n",
    "# news_encoding = news_wrapper.get_encoding(outputs)\n",
    "\n",
    "# print(news_encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
